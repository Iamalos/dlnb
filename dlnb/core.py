# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% ../nbs/00_core.ipynb 3
from __future__ import annotations
from torch import nn
import inspect 

# %% auto 0
__all__ = ['init_cnn', 'HyperParameters', 'Module']

# %% ../nbs/00_core.ipynb 4
def init_cnn(module # either nn.Linear or nn.Conv2d
            ):
    "Initialize weights for neural net layer with xavier uniform initializer."

    if type(module) == nn.Linear or type(module) == nn.Conv2d:
        nn.init.xavier_uniform_(module.weight)

# %% ../nbs/00_core.ipynb 5
class HyperParameters:
    "Saves all non-ignored arguments in a class' __init__ method as attributes."
    
    def save_hyperparameters(self, 
                             ignore = [] #  list of argument names (string) to ignore when calling `setattr`
                            ):

        # Get the next outer frame object (this frameâ€™s caller) -
        # `__init__` method.
        frame = inspect.currentframe().f_back
        # Get information about arguments passed into a particular frame.
        _, _, _, local_vars = inspect.getargvalues(frame)

        self.hparams = {
            k: v for k, v in local_vars.items()
            # ignore 'self', any variable in `ignore` list and
            # that not starts with the underscore.
            if k not in set(ignore+['self']) and not k.startswith('_')}
        for k, v in self.hparams.items():
            # set attributes of a class
            setattr(self, k, v)

# %% ../nbs/00_core.ipynb 13
class Module(nn.Module, HyperParameters):
    "The base class for all the models in the Diving into DL course"
