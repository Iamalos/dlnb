{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Basic functions and classes used in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from fastcore.basics import patch\n",
    "from fastcore.foundation import add_docs\n",
    "from __future__ import annotations\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from __future__ import annotations\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional, Callable\n",
    "from torch import nn\n",
    "from fastcore.foundation import add_docs\n",
    "import inspect \n",
    "from fastcore.basics import patch\n",
    "import collections\n",
    "from matplotlib_inline import backend_inline\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_cnn(module # either nn.Linear or nn.Conv2d\n",
    "            ):\n",
    "    \"Initialize weights for neural net layer with xavier uniform initializer.\"\n",
    "\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(2, 3)\n",
    "nn.init.ones_(model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9889, -0.2611],\n",
       "        [-0.4375, -0.6852],\n",
       "        [ 0.2779, -0.4884]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cnn(model)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HyperParameters:\n",
    "    \"Inherit from this class to save all non-ignored arguments in a class `__init__` method as attributes.\"\n",
    "    \n",
    "    def save_hyperparameters(self, \n",
    "                             ignore = [] #  list of argument names (string) to ignore when calling `setattr`\n",
    "                            ):\n",
    "\n",
    "        # Get the next outer frame object (this frameâ€™s caller) -\n",
    "        # `__init__` method.\n",
    "        frame = inspect.currentframe().f_back\n",
    "        # Get information about arguments passed into a particular frame.\n",
    "        _, _, _, local_vars = inspect.getargvalues(frame)\n",
    "\n",
    "        self.hparams = {\n",
    "            k: v for k, v in local_vars.items()\n",
    "            # ignore 'self', any variable in `ignore` list and\n",
    "            # that not starts with the underscore.\n",
    "            if k not in set(ignore+['self']) and not k.startswith('_')}\n",
    "        for k, v in self.hparams.items():\n",
    "            # set attributes of a class\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Iamalos/dlnb/blob/main/dlnb/core.py#L31){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HyperParameters.save_hyperparameters\n",
       "\n",
       ">      HyperParameters.save_hyperparameters (ignore=[])\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| ignore | list | [] | list of argument names (string) to ignore when calling `setattr` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Iamalos/dlnb/blob/main/dlnb/core.py#L31){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HyperParameters.save_hyperparameters\n",
       "\n",
       ">      HyperParameters.save_hyperparameters (ignore=[])\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| ignore | list | [] | list of argument names (string) to ignore when calling `setattr` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HyperParameters.save_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inheriting from `HyperParameters` you can save all arguments in a class `__init__` method as class attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(HyperParameters):\n",
    "    def __init__(self, name, age, sex, _internal='secret'):\n",
    "        self.save_hyperparameters(ignore=['sex'])\n",
    "        \n",
    "jack = Person(\"Billy\", 25, 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(jack.name, \"Billy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignores `self`, any variables in `ignore` list and that starts with\n",
    "the underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: jack.sex, contains=\"'Person' object has no attribute 'sex'\")\n",
    "test_fail(lambda: jack._internal, contains=\"'Person' object has no attribute '_internal'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_to_class(Class):\n",
    "    \"\"\"Adds a method to a class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interactive development and 'monkey patching'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    pass\n",
    "\n",
    "@add_to_class(Car)\n",
    "def start(self):\n",
    "    return 'Car started'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = Car()\n",
    "test_eq(car.start(), 'Car started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cpu():\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "def gpu(i: int = 0):\n",
    "    return torch.device(f'cuda:{i}')\n",
    "\n",
    "\n",
    "def get_num_gpus():\n",
    "    \"Return number of gpus.\"\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "\n",
    "def try_gpu(i: int = 0):\n",
    "    \"Return gpu(i) if exists, otherwise return cpu().\"\n",
    "    if get_num_gpus() >= i + 1:\n",
    "        return gpu(i)\n",
    "    return cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def use_svg_display():\n",
    "    \"Use the svg format to display a plot in Jupyter.\"\n",
    "    backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ProgressBoard(HyperParameters):\n",
    "    \"Plots data in animation.\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        xlabel: Optional[str] = None, # label for `x` axis\n",
    "        ylabel: Optional[str] = None, # label for `y` axis\n",
    "        xlim: Optional[float] = None, # `x` limit values\n",
    "        ylim: Optional[float] = None, # `y` limit values\n",
    "        xscale: str = 'linear', # x scale, defaults to 'linear\n",
    "        yscale: str = 'linear', # y scale, defaults to 'linear\n",
    "        ls = ['-', '--', '-.', ':'], # list of linestyles to be used\n",
    "        colors = ['C0', 'C1', 'C2', 'C3'], # list of colors to be used\n",
    "        fig: Optional[plt.Figure] = None, # figure\n",
    "        axes: Optional[plt.Axes] = None, # axes to be used for plotting. If this is not provided, creates new axes\n",
    "        figsize: Tuple[float, float] = (3.5, 2.5), # size of the figure to be displayed\n",
    "        display: bool = True # whether to show the plot\n",
    "    ):\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    \n",
    "    def _set_graph_params(self, lines, labels):\n",
    "        \n",
    "        axes = self.axes if self.axes else plt.gca()\n",
    "\n",
    "        # Set axis limits, labels and scale.\n",
    "\n",
    "        axes.set_xscale(self.xscale)\n",
    "        axes.set_yscale(self.yscale)\n",
    "\n",
    "        if self.xlim: axes.set_xlim(self.xlim)\n",
    "        if self.ylim: axes.set_ylim(self.ylim)\n",
    "\n",
    "        axes.set_xlabel(self.xlabel)\n",
    "        axes.set_ylabel(self.ylabel)\n",
    "        \n",
    "        axes.legend(lines, labels)\n",
    "\n",
    "    def draw(\n",
    "        self,\n",
    "        x, # x numeric values\n",
    "        y, # y numeric values\n",
    "        label: str, # label of a line to be plotted\n",
    "        every_n: int = 1 # over what range to average the data. Defaults to one in which case every point is plotted\n",
    "    ):\n",
    "       \n",
    "        \"Interactively plot `x` and `y`.\"\n",
    "\n",
    "        # Store pairs of x and y in a named tuple for ease of use.\n",
    "        Point = collections.namedtuple('Point', ['x', 'y'])\n",
    "\n",
    "        # Initialize `_raw_points` and `data` ordered dicts.\n",
    "        if not hasattr(self, 'data'):\n",
    "            self._raw_points = collections.OrderedDict()\n",
    "            self.data = collections.OrderedDict()\n",
    "        if label not in self.data:\n",
    "            self._raw_points[label] = []\n",
    "            self.data[label] = []\n",
    "\n",
    "        # Copy `_raw_points` and `data` for a label to temporary arrays.\n",
    "        # When points and line changes, `self._raw_points`` and `self.data`\n",
    "        # changes as well.\n",
    "        points = self._raw_points[label]\n",
    "        line = self.data[label]\n",
    "        points.append(Point(x, y))\n",
    "\n",
    "        # Accumulate points in `points` array until\n",
    "        # there are `every_n` items.\n",
    "        if len(points) != every_n:\n",
    "            return\n",
    "\n",
    "        def mean(x): return sum(x) / len(x)\n",
    "\n",
    "        # Add to line array averaged x and y points to plot.\n",
    "        line.append(Point(mean([p.x for p in points]),\n",
    "                          mean([p.y for p in points])))\n",
    "\n",
    "        # clear points array after reaching `every_n` items.\n",
    "        points.clear()\n",
    "\n",
    "        if not self.display:\n",
    "            return\n",
    "\n",
    "        use_svg_display()\n",
    "\n",
    "        # Prepare for the first plotting.\n",
    "        if self.fig is None:\n",
    "            self.fig = plt.figure(figsize=self.figsize)\n",
    "        plt_lines, labels = [], []\n",
    "\n",
    "        for (k, v), ls, color, in zip(self.data.items(), self.ls, self.colors):\n",
    "            # store in array to later call `axes.legend`\n",
    "            plt_lines.append(plt.plot(\n",
    "                [p.x for p in v],\n",
    "                [p.y for p in v],\n",
    "                linestyle=ls,\n",
    "                color=color)[0]\n",
    "            )\n",
    "            labels.append(k)\n",
    "\n",
    "        self._set_graph_params(plt_lines, labels)\n",
    "\n",
    "        display.display(self.fig)\n",
    "        # To plot on the same graph\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ProgressBoard(xlabel = 'x values', ylabel = 'y values')\n",
    "y = lambda x: x**2\n",
    "for x in range(-10, 10):\n",
    "    a.draw(x, y(x), '$x^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Module(nn.Module, HyperParameters):\n",
    "    \"The base class for all the models in the Diving into DL course\"\n",
    "\n",
    "    def __init__(\n",
    "        self: Module,\n",
    "        plot_train_per_epoch: int = 2, # number of training plot updates per one epoch\n",
    "        plot_valid_per_epoch: int = 1 # number of validation plot updates per one epoch\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.board = ProgressBoard() # ProgressBoard for plotting data\n",
    "\n",
    "\n",
    "    def loss(self: Module, \n",
    "             y_hat, # predicted y values\n",
    "             y): # real y values\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self: Module, \n",
    "                X # input tensor\n",
    "               ):\n",
    "        # make sure class has `net` attribute\n",
    "        assert hasattr(self, 'net'), 'Neural network is not defined.'\n",
    "        return self.net(X)  \n",
    "\n",
    "    def plot(self: Module,\n",
    "             key: str, # name of the metric to plot (e.g. `loss`, `accuracy`)\n",
    "             value, # value to plot\n",
    "             train: bool # train or validation\n",
    "            ):\n",
    "\n",
    "        assert hasattr(self, 'trainer'), 'Trainer is not inited.'\n",
    "        self.board.xlabel = 'epoch'\n",
    "        if train:\n",
    "            # train_batch_idx is calculated as epoch * num_train_batches,\n",
    "            # so to convert it to epochs, divide by num_train_batches.\n",
    "            # x is an epoch (x-axis for plot)\n",
    "            x = self.trainer.train_batch_idx / \\\n",
    "                self.trainer.num_train_batches\n",
    "            # frequency of updates within one epoch. E.g. if 4 batches per\n",
    "            # one epoch and `plot_train_per_epoch` is 2, then we need to\n",
    "            # update the graph every 2 batches.\n",
    "            n = self.trainer.num_train_batches / \\\n",
    "                self.plot_train_per_epoch\n",
    "        else:\n",
    "            x = self.trainer.epoch + 1\n",
    "            n = self.trainer.num_val_batches / \\\n",
    "                self.plot_valid_per_epoch\n",
    "\n",
    "        self.board.draw(x,\n",
    "                        numpy(to(value, cpu())),\n",
    "                        ('train_' if train else 'val_') + key,\n",
    "                        every_n=int(n))\n",
    "\n",
    "    def training_step(self: Module,\n",
    "                      batch # list of X and Y sampled values.\n",
    "                     ):\n",
    "            \n",
    "            # batch consists of [X, Y]\n",
    "            # so *batch[:-1] takes X values and\n",
    "            # batch[-1] takes Y values\n",
    "            loss = self.loss(self(*batch[:-1]), batch[-1])\n",
    "            self.plot('loss', loss, train=True)\n",
    "            return loss\n",
    "\n",
    "    def validation_step(self: Module,\n",
    "                        batch # List of X and Y sampled values.\n",
    "                       ):\n",
    "        loss = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('loss', loss, train=False)\n",
    "\n",
    "    def apply_init(self: Module,\n",
    "                   inputs, # Input tensor required to initialize lazy layers\n",
    "                   init: Callable = None # Initialization function for each layer\n",
    "                  ):\n",
    "       \n",
    "        self.forward(*inputs)\n",
    "        if init is not None:\n",
    "            self.net.apply(init)\n",
    "\n",
    "    def configure_optimizers(self: Module):\n",
    "        \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "add_docs(Module,\n",
    "         loss = \"Calculate loss between fitted values and observed values.\",\n",
    "         forward = \"Make a forward pass on the data.\",\n",
    "         plot = \"Plots training or validation metric.\",\n",
    "         training_step = \"Calculate loss for training batch and call `plot` method.\",\n",
    "         validation_step = \"Calculate loss for validation data and call `plot` method.\",\n",
    "         apply_init =  \"Apply `init` function to each layer of a net.\",\n",
    "         configure_optimizers = \"Configure optimizers for training the `model`.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basis building block for custom models in the course that includes the basic pipeline of training a neural net:\n",
    "`training step` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataModule(HyperParameters):\n",
    "    \"The base class for the data.\"\n",
    "    \n",
    "    def __init__(self, root: str = '../data', num_workers: int = 4):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def get_tensorloader(\n",
    "        self,\n",
    "        tensors: List[torch.Tensor], # list of tensors (e.g. Xs and ys).\n",
    "        train: bool, # rue if DataLoader for training.\n",
    "        indices: slice = slice(0, None) # slice to be used on tensors to create a DataLoader. None means to the end\n",
    "    ) -> torch.utils.data.DataLoader:\n",
    "  \n",
    "        # for each tensor in tensors select a slice given by indices\n",
    "        tensors = [tensor[indices] for tensor in tensors]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=train)\n",
    "\n",
    "    def get_dataloader(self, train: bool):\n",
    "        return NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(train=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base class for the data. A data loader is a generator that yields a batch of data every time\n",
    "it is called. The batch is then fed into the `training_step` method\n",
    "of `Module` to compute loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(DataModule,\n",
    "         get_tensorloader = \" Create torch DataLoader from the tensors.\",\n",
    "         train_dataloader = \"Return the train dataloader\",\n",
    "         val_dataloader = \"Return the validation dataloader\",\n",
    "         get_dataloader = \"not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Trainer(HyperParameters):\n",
    "    \"Base class used to train learnable parameters.\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_epochs: int, # number of epochs to run train.\n",
    "        num_gpus: int = 0, # number of gpus to use when on gpu\n",
    "        gradient_clip_value = 0\n",
    "    ):\n",
    "        self.save_hyperparameters()\n",
    "        self.gpus = [gpu(i) for i in range(min(num_gpus, get_num_gpus()))]\n",
    "\n",
    "    def prepare_data(self, data: DataModule):\n",
    "        self.train_dataloader = data.train_dataloader()\n",
    "        self.val_dataloader = data.val_dataloader()\n",
    "        self.num_train_batches = len(self.train_dataloader)\n",
    "        self.num_val_batches = (len(self.val_dataloader)\n",
    "                                if self.val_dataloader is not None else 0)\n",
    "\n",
    "    def prepare_model(self, model: Module):\n",
    "        model.trainer = self\n",
    "        model.board.xlim = [0, self.max_epochs]\n",
    "        if self.gpus:\n",
    "            model.to(self.gpus[0])\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, model: Module, data: DataModule):\n",
    "\n",
    "        self.prepare_data(data)\n",
    "        self.prepare_model(model)\n",
    "        self.optim = model.configure_optimizers()\n",
    "        \n",
    "        self.epoch = 0\n",
    "        self.train_batch_idx = 0\n",
    "        self.val_batch_idx = 0\n",
    "        # why self.epoch?\n",
    "        for self.epoch in range(self.max_epochs):\n",
    "            self.fit_epoch()\n",
    "\n",
    "    def prepare_batch(self, batch: List[Tensor] # sample of data yielded by DataLoader.\n",
    "                     ):\n",
    "        \n",
    "        if self.gpus:\n",
    "            batch = [a.to(self.gpus[0]) for a in batch]\n",
    "        return batch\n",
    "\n",
    "    def fit_epoch(self):\n",
    "        \n",
    "        # from nn.Module - sets the model in a training mode\n",
    "        self.model.train()\n",
    "        \n",
    "        for batch in self.train_dataloader:\n",
    "            loss = self.model.training_step(self.prepare_batch(batch))\n",
    "            self.optim.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                loss.backward()\n",
    "                if self.gradient_clip_value > 0:\n",
    "                    print(\"NOT IMPLEMENTED YET\")\n",
    "                    self.clip_gradients(self.gradient_clip_value, self.model)\n",
    "                self.optim.step()\n",
    "            self.train_batch_idx += 1\n",
    "            \n",
    "        if self.val_dataloader is None:\n",
    "            return\n",
    "        # from nn.Module - sets the model in a training mode\n",
    "        self.model.eval()\n",
    "        for batch in self.val_dataloader:\n",
    "            with torch.no_grad():\n",
    "                self.model.validation_step(self.prepare_batch(batch))\n",
    "            self.val_batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Trainer,\n",
    "         prepare_data = \"Prepare train and validation dataloaders\",\n",
    "         prepare_model = \"Set trainer and model\",\n",
    "         fit = \"Fit the model on data\",\n",
    "         prepare_batch = \"Prepares the batch before training loop\",\n",
    "         fit_epoch = \"Fit each training and (optonally) validation epoch\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Timer:\n",
    "    \"Record multiple running times.\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"Inits Timer with empty array of `times` and starts it.\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self) -> None:\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self) -> None:\n",
    "        self.times.append(time.time()-self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self) -> float:\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def cumsum(self) -> List[float]:\n",
    "        # casts list to numpy array to use `cumsum` f-n\n",
    "        # then casts back to python list\n",
    "        return np.array(self.times).cumsum().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "add_docs(Timer,\n",
    "         start = \"Start the timer\",\n",
    "         stop = \"Stop the timer and record the time in a list\",\n",
    "         avg = \"Return the average time\",\n",
    "         cumsum = \"Return the accumulated time\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Timer.start` to start the timer and `Timer.stop` to end it. `Timer.avg` calculates the average running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer()\n",
    "timer.start()\n",
    "time.sleep(0.5)\n",
    "\n",
    "timer.stop()\n",
    "timer.start()\n",
    "\n",
    "time.sleep(1)\n",
    "timer.stop()\n",
    "\n",
    "test_close(timer.avg(), (0.5+1)/2, eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Accumulator:\n",
    "    \"Accumulates sums over `n` variables.\"\n",
    "\n",
    "    def __init__(self, n: int # length of an array\n",
    "                ):\n",
    "        \"Inititalize with zeros an array of size `n`\"\n",
    "\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        \"Add new values to each corresponding position in the array.\"\n",
    "\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Set all data entries of data to zero\"\"\"\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"Getter - simply return an element by index from self.data.\"\"\"\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulates statistics over an array of lengths `n`. Each entry in an array represents `characteristic` over which new items to repsective array positions will be summed over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Accumulator(3)\n",
    "a.add(1,2,3)\n",
    "test_eq(a.data, [1.0, 2.0, 3.0])\n",
    "\n",
    "a.add(1,1,1)\n",
    "test_eq(a.data, [2.0, 3.0, 4.0])\n",
    "\n",
    "a.reset()\n",
    "test_eq(a.data, [0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
